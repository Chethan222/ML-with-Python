{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd308d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d9ed18",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5841007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9400e+02, 1.6200e+03, 1.6200e+03, ..., 5.0000e+00, 9.2000e+01,\n",
       "        0.0000e+00],\n",
       "       [1.1430e+03, 2.1600e+03, 2.1600e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [2.0590e+03, 2.1600e+03, 2.1600e+03, ..., 0.0000e+00, 3.8800e+02,\n",
       "        0.0000e+00],\n",
       "       ...,\n",
       "       [3.1134e+04, 2.1600e+03, 2.1600e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       [3.2832e+04, 1.6200e+03, 1.6200e+03, ..., 0.0000e+00, 9.0000e+01,\n",
       "        0.0000e+00],\n",
       "       [2.5100e+02, 1.6740e+03, 3.3480e+03, ..., 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(\"Audiobooks_data.csv\",delimiter=\",\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dbcd400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1620.  , 1620.  ,   19.73, ..., 1603.8 ,    5.  ,   92.  ],\n",
       "       [2160.  , 2160.  ,    5.33, ...,    0.  ,    0.  ,    0.  ],\n",
       "       [2160.  , 2160.  ,    5.33, ...,    0.  ,    0.  ,  388.  ],\n",
       "       ...,\n",
       "       [2160.  , 2160.  ,    6.14, ...,    0.  ,    0.  ,    0.  ],\n",
       "       [1620.  , 1620.  ,    5.33, ...,  615.6 ,    0.  ,   90.  ],\n",
       "       [1674.  , 3348.  ,    5.33, ...,    0.  ,    0.  ,    0.  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unScaledData = data[:,1:-1]\n",
    "unScaledData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112229a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = data[:,-1]\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f26f85",
   "metadata": {},
   "source": [
    "### Balancing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ffa429",
   "metadata": {},
   "outputs": [],
   "source": [
    "numOneTargets = int(np.sum(targets))\n",
    "counter = 0\n",
    "indicesToRemove = []\n",
    "\n",
    "#Balancing the the 1s and 0s\n",
    "for i in range(targets.shape[0]):\n",
    "    if targets[i] == 0:\n",
    "        counter +=1\n",
    "        \n",
    "        if counter > numOneTargets :\n",
    "            indicesToRemove.append(i)\n",
    "        \n",
    "balancedData = np.delete(unScaledData,indicesToRemove,axis=0)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2997217",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc46f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedData = preprocessing.scale(balancedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc32229",
   "metadata": {},
   "source": [
    "### Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "157bb68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffledIndices = np.arange(preprocessedData.shape[0])\n",
    "np.random.shuffle(shuffledIndices)\n",
    "\n",
    "shuffledInputs = preprocessedData[shuffledIndices]\n",
    "shuffledTargets = targets[shuffledIndices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed629e2",
   "metadata": {},
   "source": [
    "### Splitting the data into training and testing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "118e2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = shuffledInputs.shape[0]\n",
    "trainSampleCount = int(0.8*m)\n",
    "validationSampleCount = int(m*0.1)\n",
    "testSampleCount = m - (trainSampleCount+validationSampleCount)\n",
    "\n",
    "trainInputs = shuffledInputs[:trainSampleCount]\n",
    "trainTargets = shuffledTargets[:trainSampleCount]\n",
    "\n",
    "validationInputs = shuffledInputs[trainSampleCount:trainSampleCount+validationSampleCount]\n",
    "validationTargets = shuffledTargets[trainSampleCount:trainSampleCount+validationSampleCount]\n",
    "\n",
    "\n",
    "testInputs = shuffledInputs[trainSampleCount+validationSampleCount:]\n",
    "testTargets = shuffledTargets[trainSampleCount+validationSampleCount:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765a54de",
   "metadata": {},
   "source": [
    "### Saving the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed5d627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('Audiobook_TrainData',inputs=trainInputs,targets=trainTargets)\n",
    "np.savez('Audiobook_TestData',inputs=testInputs,targets=testTargets)\n",
    "np.savez('Audiobook_ValidationData',inputs=validationInputs,targets=validationTargets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f6679",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50b84b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Loading data\n",
    "npzTrainData = np.load(\"Audiobook_TrainData.npz\")\n",
    "npzTestData = np.load(\"Audiobook_TestData.npz\")\n",
    "npzValData = np.load(\"Audiobook_ValidationData.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cc6c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = npzTrainData['inputs'].astype(np.float64)\n",
    "Y = npzTrainData['targets'].astype(np.int64)\n",
    "valX = npzValData['inputs'].astype(np.float64)\n",
    "valY = npzValData['targets'].astype(np.int64)\n",
    "testX = npzTestData['inputs'].astype(np.float64)\n",
    "testY = npzTestData['targets'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5425a95",
   "metadata": {},
   "source": [
    "### Creating Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56f8f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 - 1s - loss: 0.5210 - accuracy: 0.7977 - val_loss: 0.4783 - val_accuracy: 0.7875 - 1s/epoch - 32ms/step\n",
      "Epoch 2/100\n",
      "36/36 - 0s - loss: 0.4555 - accuracy: 0.8053 - val_loss: 0.4612 - val_accuracy: 0.7875 - 153ms/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "36/36 - 0s - loss: 0.4403 - accuracy: 0.8041 - val_loss: 0.4519 - val_accuracy: 0.7942 - 154ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "36/36 - 0s - loss: 0.4326 - accuracy: 0.8044 - val_loss: 0.4463 - val_accuracy: 0.7919 - 154ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "36/36 - 0s - loss: 0.4281 - accuracy: 0.8050 - val_loss: 0.4382 - val_accuracy: 0.8009 - 162ms/epoch - 5ms/step\n",
      "Epoch 6/100\n",
      "36/36 - 0s - loss: 0.4219 - accuracy: 0.8039 - val_loss: 0.4367 - val_accuracy: 0.7919 - 148ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "36/36 - 0s - loss: 0.4191 - accuracy: 0.8097 - val_loss: 0.4313 - val_accuracy: 0.7942 - 165ms/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "36/36 - 0s - loss: 0.4156 - accuracy: 0.8086 - val_loss: 0.4299 - val_accuracy: 0.7942 - 153ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "36/36 - 0s - loss: 0.4124 - accuracy: 0.8089 - val_loss: 0.4266 - val_accuracy: 0.7964 - 148ms/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "36/36 - 0s - loss: 0.4113 - accuracy: 0.8106 - val_loss: 0.4253 - val_accuracy: 0.7987 - 157ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "36/36 - 0s - loss: 0.4103 - accuracy: 0.8122 - val_loss: 0.4312 - val_accuracy: 0.7919 - 162ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "36/36 - 0s - loss: 0.4075 - accuracy: 0.8111 - val_loss: 0.4287 - val_accuracy: 0.7942 - 163ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "36/36 - 0s - loss: 0.4070 - accuracy: 0.8100 - val_loss: 0.4239 - val_accuracy: 0.8031 - 159ms/epoch - 4ms/step\n",
      "Epoch 14/100\n",
      "36/36 - 0s - loss: 0.4048 - accuracy: 0.8153 - val_loss: 0.4247 - val_accuracy: 0.7964 - 156ms/epoch - 4ms/step\n",
      "Epoch 15/100\n",
      "36/36 - 0s - loss: 0.4046 - accuracy: 0.8150 - val_loss: 0.4219 - val_accuracy: 0.8009 - 151ms/epoch - 4ms/step\n",
      "Epoch 16/100\n",
      "36/36 - 0s - loss: 0.4017 - accuracy: 0.8125 - val_loss: 0.4227 - val_accuracy: 0.8009 - 157ms/epoch - 4ms/step\n",
      "Epoch 17/100\n",
      "36/36 - 0s - loss: 0.4002 - accuracy: 0.8150 - val_loss: 0.4220 - val_accuracy: 0.7919 - 152ms/epoch - 4ms/step\n",
      "Epoch 18/100\n",
      "36/36 - 0s - loss: 0.4024 - accuracy: 0.8136 - val_loss: 0.4223 - val_accuracy: 0.7942 - 150ms/epoch - 4ms/step\n",
      "Epoch 19/100\n",
      "36/36 - 0s - loss: 0.3995 - accuracy: 0.8164 - val_loss: 0.4216 - val_accuracy: 0.7987 - 147ms/epoch - 4ms/step\n",
      "Epoch 20/100\n",
      "36/36 - 0s - loss: 0.3987 - accuracy: 0.8159 - val_loss: 0.4227 - val_accuracy: 0.7987 - 154ms/epoch - 4ms/step\n",
      "Epoch 21/100\n",
      "36/36 - 0s - loss: 0.3965 - accuracy: 0.8178 - val_loss: 0.4205 - val_accuracy: 0.7964 - 152ms/epoch - 4ms/step\n",
      "Epoch 22/100\n",
      "36/36 - 0s - loss: 0.3952 - accuracy: 0.8173 - val_loss: 0.4251 - val_accuracy: 0.7964 - 167ms/epoch - 5ms/step\n",
      "Epoch 23/100\n",
      "36/36 - 0s - loss: 0.3952 - accuracy: 0.8175 - val_loss: 0.4237 - val_accuracy: 0.7852 - 159ms/epoch - 4ms/step\n",
      "Epoch 24/100\n",
      "36/36 - 0s - loss: 0.3966 - accuracy: 0.8167 - val_loss: 0.4267 - val_accuracy: 0.7919 - 149ms/epoch - 4ms/step\n",
      "Epoch 25/100\n",
      "36/36 - 0s - loss: 0.3949 - accuracy: 0.8189 - val_loss: 0.4237 - val_accuracy: 0.7987 - 148ms/epoch - 4ms/step\n",
      "Epoch 26/100\n",
      "36/36 - 0s - loss: 0.3935 - accuracy: 0.8203 - val_loss: 0.4253 - val_accuracy: 0.7942 - 165ms/epoch - 5ms/step\n",
      "Epoch 27/100\n",
      "36/36 - 0s - loss: 0.3913 - accuracy: 0.8203 - val_loss: 0.4235 - val_accuracy: 0.7987 - 160ms/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20013318bb0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inputSize = 10\n",
    "outputSize = 2\n",
    "hiddenLayerSize = 50\n",
    "\n",
    "#Stopping before overfit\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(patience=6)\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(hiddenLayerSize,activation='relu'),\n",
    "                            tf.keras.layers.Dense(hiddenLayerSize,activation='relu'),\n",
    "                            tf.keras.layers.Dense(outputSize,activation='softmax')\n",
    "                            ])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "batchSize = 100\n",
    "maxEpochs = 100\n",
    "model.fit(X,\n",
    "          Y,\n",
    "          batch_size=batchSize,\n",
    "          epochs=maxEpochs,\n",
    "          validation_data=(valX,valY),\n",
    "          verbose=2,\n",
    "          callbacks=[earlyStop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9be9d7",
   "metadata": {},
   "source": [
    "### Test on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3574f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8147\n",
      "\n",
      "Train Loss: 0.4.\n",
      "Test accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "testLoss,testAccuracy = model.evaluate(testX,testY)\n",
    "print(\"\\nTrain Loss: {}.\\nTest accuracy: {}\".format(round(testLoss,2),round(testAccuracy,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac85a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
